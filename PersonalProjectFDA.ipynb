{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal FDA Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Collection\n",
    "import yfinance as yf\n",
    "import wrds\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# Valuation Models\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# User Interface (Optional)\n",
    "import streamlit as st\n",
    "\n",
    "# Additional Tools\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 10 stock tickers\n",
    "tickers = [\"AAPL\", \"MSFT\", \"KO\", \"AMZN\", \"TSLA\", \"NVDA\", \"META\", \"JNJ\", \"PG\", \"DIS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. WRDS Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n",
      "Sample Data from WRDS:\n",
      "    gvkey   tic    datadate        at        lt      ebit      revt       ni  \\\n",
      "0  001690  AAPL  2018-09-30  365725.0  258578.0   70662.0  265359.0  59531.0   \n",
      "1  001690  AAPL  2019-09-30  338516.0  248028.0   63930.0  260174.0  55256.0   \n",
      "2  001690  AAPL  2020-09-30  323888.0  258549.0   66288.0  274515.0  57411.0   \n",
      "3  001690  AAPL  2021-09-30  351002.0  287912.0  108949.0  365817.0  94680.0   \n",
      "4  001690  AAPL  2022-09-30  352755.0  302083.0  119437.0  394328.0  99803.0   \n",
      "\n",
      "      oibdp     capx  dvpsp_f       csho  prcc_f       che  naicsh  \n",
      "0   79962.0  13313.0    2.720   4754.986  225.74   66301.0  334220  \n",
      "1   75230.0  10495.0    3.000   4443.236  223.97  100580.0  334220  \n",
      "2   75988.0   7309.0    0.795  16976.763  115.81   90979.0  334220  \n",
      "3  118449.0  11085.0    0.850  16426.786  141.50   62639.0  334220  \n",
      "4  128137.0  10708.0    0.900  15943.425  138.20   48304.0  334220  \n"
     ]
    }
   ],
   "source": [
    "# Connect to WRDS\n",
    "db = wrds.Connection()\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT a.gvkey, a.tic, a.datadate, a.at, a.lt, a.ebit, a.revt, a.ni, \n",
    "           a.oibdp, a.capx, a.dvpsp_f, a.csho, a.prcc_f, a.che, a.naicsh\n",
    "    FROM comp.funda AS a\n",
    "    WHERE a.indfmt = 'INDL'\n",
    "      AND a.datafmt = 'STD'\n",
    "      AND a.popsrc = 'D'\n",
    "      AND a.consol = 'C'\n",
    "      AND a.datadate >= '2018-01-01'\n",
    "      AND a.tic IN ({', '.join([f\"'{ticker}'\" for ticker in tickers])})\n",
    "\"\"\"\n",
    "compustat_data = db.raw_sql(query)\n",
    "\n",
    "# Preprocess WRDS data\n",
    "compustat_data['tic'] = compustat_data['tic'].str.strip()\n",
    "compustat_data.to_csv(\"financial_data_10_companies.csv\", index=False)\n",
    "\n",
    "# Print a sample to confirm the data is correct\n",
    "print(\"Sample Data from WRDS:\")\n",
    "print(compustat_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividends data found for AMZN.\n",
      "No dividends data found for TSLA.\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store data for each ticker\n",
    "historical_prices_data = {}\n",
    "dividends_data = {}\n",
    "financials_data = {}\n",
    "balance_sheet_data = {}\n",
    "cashflow_data = {}\n",
    "\n",
    "# Iterate through each ticker in the list\n",
    "for ticker in tickers:  # tickers should be a list of ticker symbols\n",
    "    stock = yf.Ticker(ticker)\n",
    "    \n",
    "    try:\n",
    "        # Fetch historical prices\n",
    "        historical_prices = stock.history(period=\"5y\")  # Last 5 years of stock prices\n",
    "        if not historical_prices.empty:\n",
    "            historical_prices_data[ticker] = historical_prices\n",
    "            historical_prices.to_csv(f\"{ticker}_historical_prices.csv\", index=True)\n",
    "        else:\n",
    "            print(f\"No historical prices found for {ticker}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching historical prices for {ticker}: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch dividend history\n",
    "        dividends = stock.dividends\n",
    "        if not dividends.empty:\n",
    "            dividends_data[ticker] = dividends\n",
    "            dividends.to_csv(f\"{ticker}_dividends.csv\", index=True)\n",
    "        else:\n",
    "            print(f\"No dividends data found for {ticker}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching dividends for {ticker}: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch financials\n",
    "        financials = stock.financials\n",
    "        if not financials.empty:\n",
    "            financials_data[ticker] = financials\n",
    "            financials.to_csv(f\"{ticker}_financials.csv\", index=True)\n",
    "        else:\n",
    "            print(f\"No financials data found for {ticker}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching financials for {ticker}: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch balance sheet\n",
    "        balance_sheet = stock.balance_sheet\n",
    "        if not balance_sheet.empty:\n",
    "            balance_sheet_data[ticker] = balance_sheet\n",
    "            balance_sheet.to_csv(f\"{ticker}_balance_sheet.csv\", index=True)\n",
    "        else:\n",
    "            print(f\"No balance sheet data found for {ticker}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching balance sheet for {ticker}: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Fetch cash flow statement\n",
    "        cashflow = stock.cashflow\n",
    "        if not cashflow.empty:\n",
    "            cashflow_data[ticker] = cashflow\n",
    "            cashflow.to_csv(f\"{ticker}_cashflow.csv\", index=True)\n",
    "        else:\n",
    "            print(f\"No cash flow data found for {ticker}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching cash flow data for {ticker}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate and Match Tickers with Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated Tickers (Fuzzy Matched):\n",
      "['AAPL', 'MSFT', 'KO', 'AMZN', 'TSLA', 'NVDA', 'META', 'JNJ', 'PG', 'DIS']\n"
     ]
    }
   ],
   "source": [
    "# Match user-provided tickers to WRDS tickers\n",
    "wrds_tickers = compustat_data['tic'].unique()\n",
    "validated_tickers = [process.extractOne(ticker, wrds_tickers)[0] for ticker in tickers]\n",
    "\n",
    "print(\"Validated Tickers (Fuzzy Matched):\")\n",
    "print(validated_tickers)\n",
    "\n",
    "# Update WRDS data with matched tickers\n",
    "compustat_data['best_match'] = compustat_data['tic'].apply(\n",
    "    lambda x: process.extractOne(x, validated_tickers)[0] if pd.notnull(x) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for AAPL...\n",
      "Historical prices saved for AAPL.\n",
      "Dividends data saved for AAPL.\n",
      "Fetching data for MSFT...\n",
      "Historical prices saved for MSFT.\n",
      "Dividends data saved for MSFT.\n",
      "Fetching data for KO...\n",
      "Historical prices saved for KO.\n",
      "Dividends data saved for KO.\n",
      "Fetching data for AMZN...\n",
      "Historical prices saved for AMZN.\n",
      "No dividend data found for AMZN.\n",
      "Fetching data for TSLA...\n",
      "Historical prices saved for TSLA.\n",
      "No dividend data found for TSLA.\n",
      "Fetching data for NVDA...\n",
      "Historical prices saved for NVDA.\n",
      "Dividends data saved for NVDA.\n",
      "Fetching data for META...\n",
      "Historical prices saved for META.\n",
      "Dividends data saved for META.\n",
      "Fetching data for JNJ...\n",
      "Historical prices saved for JNJ.\n",
      "Dividends data saved for JNJ.\n",
      "Fetching data for PG...\n",
      "Historical prices saved for PG.\n",
      "Dividends data saved for PG.\n",
      "Fetching data for DIS...\n",
      "Historical prices saved for DIS.\n",
      "Dividends data saved for DIS.\n"
     ]
    }
   ],
   "source": [
    "# Fetch stock data from Yahoo Finance\n",
    "historical_data = {}\n",
    "dividends_data = {}\n",
    "\n",
    "# Initialize dictionaries to store data\n",
    "historical_data = {}\n",
    "dividends_data = {}\n",
    "\n",
    "# Fetch data for each validated ticker\n",
    "for ticker in validated_tickers:\n",
    "    print(f\"Fetching data for {ticker}...\")\n",
    "    stock = yf.Ticker(ticker)\n",
    "    \n",
    "    try:\n",
    "        # Fetch historical prices\n",
    "        historical_prices = stock.history(period=\"5y\")\n",
    "        if not historical_prices.empty:\n",
    "            historical_data[ticker] = historical_prices\n",
    "            historical_prices.to_csv(f\"{ticker}_historical_prices.csv\", index=True)\n",
    "            print(f\"Historical prices saved for {ticker}.\")\n",
    "        else:\n",
    "            print(f\"No historical prices found for {ticker}.\")\n",
    "        \n",
    "        # Fetch dividend data\n",
    "        dividends = stock.dividends\n",
    "        if not dividends.empty:\n",
    "            dividends_data[ticker] = dividends\n",
    "            dividends.to_csv(f\"{ticker}_dividends.csv\", index=True)\n",
    "            print(f\"Dividends data saved for {ticker}.\")\n",
    "        else:\n",
    "            print(f\"No dividend data found for {ticker}.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data for Valuation Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete. FCF and valuation data saved.\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataFrames for combined results\n",
    "fcf_data = pd.DataFrame()\n",
    "valuation_data = pd.DataFrame()\n",
    "\n",
    "# Process each company\n",
    "for ticker in validated_tickers:\n",
    "    # Filter data for this ticker\n",
    "    company_data = compustat_data[compustat_data['tic'] == ticker]\n",
    "    \n",
    "    # Ensure required columns exist\n",
    "    required_columns = ['oibdp', 'capx', 'csho', 'dvpsp_f', 'ni', 'at', 'lt']\n",
    "    if not all(col in company_data.columns for col in required_columns):\n",
    "        print(f\"Missing required columns for {ticker}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate Free Cash Flow (FCF)\n",
    "    company_data['FCF'] = company_data['oibdp'] - company_data['capx']\n",
    "    \n",
    "    # Handle zero or missing values in `ni` and `oibdp` for valuation multiples\n",
    "    company_data['P/E'] = (company_data['csho'] * company_data['dvpsp_f']) / company_data['ni'].replace(0, np.nan)\n",
    "    company_data['EV/EBITDA'] = (company_data['at'] - company_data['lt']) / company_data['oibdp'].replace(0, np.nan)\n",
    "    \n",
    "    # Append to combined DataFrames\n",
    "    fcf_data = pd.concat([fcf_data, company_data[['tic', 'datadate', 'FCF']].reset_index(drop=True)])\n",
    "    valuation_data = pd.concat([valuation_data, company_data[['tic', 'datadate', 'P/E', 'EV/EBITDA']].reset_index(drop=True)])\n",
    "\n",
    "# Save processed data\n",
    "fcf_data.to_csv(\"fcf_data.csv\", index=False)\n",
    "valuation_data.to_csv(\"valuation_data.csv\", index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Data processing complete. FCF and valuation data saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Dividend Growth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dividends for AAPL...\n",
      "Processing dividends for MSFT...\n",
      "Processing dividends for KO...\n",
      "Processing dividends for NVDA...\n",
      "Processing dividends for META...\n",
      "Processing dividends for JNJ...\n",
      "Processing dividends for PG...\n",
      "Processing dividends for DIS...\n",
      "Dividend growth data processing complete. Saved to dividend_growth_data.csv.\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataFrame for dividend growth rates\n",
    "dividend_growth_data = pd.DataFrame()\n",
    "\n",
    "for ticker, dividends in dividends_data.items():\n",
    "    if not dividends.empty:\n",
    "        print(f\"Processing dividends for {ticker}...\")\n",
    "        # Convert to DataFrame and calculate growth rate\n",
    "        dividends_df = dividends.to_frame().reset_index()\n",
    "        dividends_df.columns = ['Date', 'Dividends']  # Standardize column names\n",
    "        dividends_df['Date'] = pd.to_datetime(dividends_df['Date'])  # Ensure datetime format\n",
    "        if len(dividends_df) > 1:  # Only calculate growth rate if there's more than one record\n",
    "            dividends_df['Growth Rate'] = dividends_df['Dividends'].pct_change()\n",
    "        else:\n",
    "            dividends_df['Growth Rate'] = None  # No growth rate for single record\n",
    "        \n",
    "        # Add ticker identifier\n",
    "        dividends_df['Ticker'] = ticker\n",
    "        \n",
    "        # Append to combined DataFrame\n",
    "        dividend_growth_data = pd.concat([dividend_growth_data, dividends_df.reset_index(drop=True)])\n",
    "    else:\n",
    "        print(f\"No dividends data for {ticker}.\")\n",
    "\n",
    "# Save dividend growth data\n",
    "dividend_growth_data.to_csv(\"dividend_growth_data.csv\", index=False)\n",
    "\n",
    "# Print confirmation\n",
    "print(\"Dividend growth data processing complete. Saved to dividend_growth_data.csv.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Free Cash Flow Data:\n",
      "                 FCF\n",
      "count      65.000000\n",
      "mean    26232.298923\n",
      "std     31311.260693\n",
      "min    -25210.000000\n",
      "25%      9392.000000\n",
      "50%     14043.000000\n",
      "75%     33326.000000\n",
      "max    121969.000000\n",
      "\n",
      "Summary of Valuation Multiples Data:\n",
      "             P/E  EV/EBITDA\n",
      "count  65.000000  65.000000\n",
      "mean    0.284872   2.893145\n",
      "std     0.367336   2.113563\n",
      "min    -0.556145   0.395452\n",
      "25%     0.000000   1.875584\n",
      "50%     0.158044   2.282145\n",
      "75%     0.572033   3.002157\n",
      "max     1.862334  11.656100\n",
      "\n",
      "Summary of Dividend Growth Data:\n",
      "        Dividends  Growth Rate\n",
      "count  125.000000   117.000000\n",
      "mean     0.555660     0.024592\n",
      "std      0.374797     0.160186\n",
      "min      0.004000    -0.659091\n",
      "25%      0.230000     0.000000\n",
      "50%      0.500000     0.000000\n",
      "75%      0.880000     0.000000\n",
      "max      1.240000     1.500000\n",
      "\n",
      "Key Insights from Processed Data:\n",
      "Highest FCF:\n",
      "    tic    datadate       FCF\n",
      "6  AAPL  2024-09-30  121969.0\n",
      "6  MSFT  2024-06-30   84956.0\n",
      "6  NVDA  2024-01-31   33411.0\n",
      "6    PG  2024-06-30   19863.0\n",
      "6   DIS  2024-09-30   11492.0\n",
      "\n",
      "Lowest FCF:\n",
      "    tic    datadate       FCF\n",
      "4  AAPL  2022-09-30  117429.0\n",
      "4  MSFT  2022-06-30   74223.0\n",
      "4    KO  2022-12-31   11898.0\n",
      "4  AMZN  2022-12-31  -25210.0\n",
      "4  TSLA  2022-12-31   10416.0\n",
      "4  NVDA  2022-01-31   10239.0\n",
      "4  META  2022-12-31   10810.0\n",
      "4   JNJ  2022-12-31   28427.0\n",
      "4    PG  2022-06-30   17713.0\n",
      "4   DIS  2022-09-30    8013.0\n",
      "\n",
      "Company with the Highest P/E Ratio:\n",
      "    tic    datadate       P/E  EV/EBITDA\n",
      "1  AAPL  2019-09-30  0.241235   1.202818\n",
      "1  MSFT  2019-06-30  0.350596   1.875584\n",
      "1    KO  2019-12-31  0.767713   1.774880\n",
      "1  AMZN  2019-12-31  0.000000   2.076141\n",
      "1  TSLA  2019-12-31 -0.000000   3.708276\n",
      "1  NVDA  2019-01-31  0.089268   2.272993\n",
      "1  META  2019-12-31  0.000000   2.909871\n",
      "1   JNJ  2019-12-31  0.652947   2.114149\n",
      "1    PG  2019-06-30  1.862334   2.735998\n",
      "1   DIS  2019-09-30  0.286912   6.361061\n",
      "\n",
      "Company with the Highest Dividend Growth Rate:\n",
      "                        Date  Dividends  Growth Rate Ticker\n",
      "17 2024-05-10 00:00:00-04:00      0.250     0.041667   AAPL\n",
      "17 2024-05-15 00:00:00-04:00      0.750     0.000000   MSFT\n",
      "17 2024-06-14 00:00:00-04:00      0.485     0.000000     KO\n",
      "17 2024-06-11 00:00:00-04:00      0.010     1.500000   NVDA\n",
      "17 2024-05-20 00:00:00-04:00      1.240     0.042017    JNJ\n",
      "17 2024-04-18 00:00:00-04:00      1.007     0.070138     PG\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summarize Free Cash Flow (FCF) Data\n",
    "print(\"Summary of Free Cash Flow Data:\")\n",
    "print(fcf_data.describe())\n",
    "\n",
    "# Summarize Valuation Multiples Data\n",
    "print(\"\\nSummary of Valuation Multiples Data:\")\n",
    "print(valuation_data.describe())\n",
    "\n",
    "# Summarize Dividend Growth Data\n",
    "if not dividend_growth_data.empty:\n",
    "    print(\"\\nSummary of Dividend Growth Data:\")\n",
    "    print(dividend_growth_data.describe())\n",
    "\n",
    "# Key Insights\n",
    "print(\"\\nKey Insights from Processed Data:\")\n",
    "\n",
    "# Highest and Lowest FCF\n",
    "highest_fcf = fcf_data.loc[fcf_data['FCF'].idxmax()]\n",
    "lowest_fcf = fcf_data.loc[fcf_data['FCF'].idxmin()]\n",
    "print(f\"Highest FCF:\\n{highest_fcf}\\n\")\n",
    "print(f\"Lowest FCF:\\n{lowest_fcf}\\n\")\n",
    "\n",
    "# Companies with Highest P/E Ratio\n",
    "highest_pe = valuation_data.loc[valuation_data['P/E'].idxmax()]\n",
    "print(f\"Company with the Highest P/E Ratio:\\n{highest_pe}\\n\")\n",
    "\n",
    "# Companies with the Highest Dividend Growth Rate\n",
    "if not dividend_growth_data.empty:\n",
    "    highest_div_growth = dividend_growth_data.loc[dividend_growth_data['Growth Rate'].idxmax()]\n",
    "    print(f\"Company with the Highest Dividend Growth Rate:\\n{highest_div_growth}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Free Cash Flow Data for DCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Free Cash Flow Data (Year-by-Year):\n",
      "    tic   datadate       FCF\n",
      "0  AAPL 2018-09-30   66649.0\n",
      "1  AAPL 2019-09-30   64735.0\n",
      "2  AAPL 2020-09-30   68679.0\n",
      "3  AAPL 2021-09-30  107364.0\n",
      "4  AAPL 2022-09-30  117429.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate Free Cash Flow (FCF) for each company\n",
    "compustat_data['FCF'] = compustat_data['oibdp'] - compustat_data['capx']\n",
    "\n",
    "# Ensure data is sorted chronologically\n",
    "compustat_data['datadate'] = pd.to_datetime(compustat_data['datadate'])  # Convert to datetime\n",
    "compustat_data = compustat_data.sort_values(by=['tic', 'datadate'])\n",
    "\n",
    "# Group data by company and retain year-by-year FCF\n",
    "fcf_data = compustat_data[['tic', 'datadate', 'FCF']]\n",
    "\n",
    "# Save to CSV\n",
    "fcf_data.to_csv(\"fcf_data_detailed.csv\", index=False)\n",
    "\n",
    "# Print a sample of the detailed FCF data\n",
    "print(\"Detailed Free Cash Flow Data (Year-by-Year):\")\n",
    "print(fcf_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Valuation Multiples for CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valuation Multiples Data:\n",
      "    tic   datadate        P/E  EV/EBITDA\n",
      "0  AAPL 2024-09-30  37.575863   0.433357\n",
      "1  AMZN 2023-12-31  51.851866   2.975576\n",
      "2   DIS 2024-09-30  35.055567   6.242428\n",
      "3   JNJ 2023-12-31  10.732666   2.261261\n",
      "4    KO 2023-12-31  23.695206   1.906348\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary columns exist\n",
    "required_columns = ['csho', 'prcc_f', 'ni', 'at', 'lt', 'oibdp']\n",
    "if not all(col in compustat_data.columns for col in required_columns):\n",
    "    raise ValueError(\"One or more required columns are missing from the data.\")\n",
    "\n",
    "# Calculate Valuation Multiples\n",
    "compustat_data['P/E'] = (compustat_data['csho'] * compustat_data['prcc_f']) / compustat_data['ni'].replace(0, np.nan)\n",
    "compustat_data['EV/EBITDA'] = (compustat_data['at'] - compustat_data['lt']) / compustat_data['oibdp'].replace(0, np.nan)\n",
    "\n",
    "# Filter relevant columns\n",
    "valuation_data = compustat_data[['tic', 'datadate', 'P/E', 'EV/EBITDA']]\n",
    "\n",
    "# Keep the most recent valuation multiples for each company\n",
    "valuation_data = valuation_data.sort_values(by=['tic', 'datadate']).groupby('tic').last().reset_index()\n",
    "\n",
    "# Save to CSV\n",
    "valuation_data.to_csv(\"valuation_data.csv\", index=False)\n",
    "\n",
    "# Print sample data\n",
    "print(\"Valuation Multiples Data:\")\n",
    "print(valuation_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividend Growth Rate Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dividend data for AAPL...\n",
      "Processing dividend data for MSFT...\n",
      "Processing dividend data for KO...\n",
      "Processing dividend data for NVDA...\n",
      "Processing dividend data for META...\n",
      "Processing dividend data for JNJ...\n",
      "Processing dividend data for PG...\n",
      "Processing dividend data for DIS...\n",
      "Dividend Growth Data:\n",
      "                       Date  Dividends  Growth Rate Ticker\n",
      "0 2020-02-07 00:00:00-05:00     0.1925          NaN   AAPL\n",
      "1 2020-05-08 00:00:00-04:00     0.2050     0.064935   AAPL\n",
      "2 2020-08-07 00:00:00-04:00     0.2050     0.000000   AAPL\n",
      "3 2020-11-06 00:00:00-05:00     0.2050     0.000000   AAPL\n",
      "4 2021-02-05 00:00:00-05:00     0.2050     0.000000   AAPL\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataFrame for dividend growth rates\n",
    "dividend_growth_data = pd.DataFrame()\n",
    "\n",
    "# Process dividends for each company\n",
    "for ticker, dividends in dividends_data.items():\n",
    "    if not dividends.empty:\n",
    "        print(f\"Processing dividend data for {ticker}...\")\n",
    "        # Convert dividend data to DataFrame\n",
    "        dividends_df = dividends.to_frame().reset_index()\n",
    "        dividends_df.columns = ['Date', 'Dividends']  # Rename columns for consistency\n",
    "        dividends_df['Date'] = pd.to_datetime(dividends_df['Date'])  # Ensure proper datetime format\n",
    "        dividends_df['Dividends'] = pd.to_numeric(dividends_df['Dividends'], errors='coerce')  # Ensure numeric\n",
    "        \n",
    "        if len(dividends_df) > 1:  # Ensure sufficient data for growth rate calculation\n",
    "            # Calculate Dividend Growth Rate\n",
    "            dividends_df['Growth Rate'] = dividends_df['Dividends'].pct_change()\n",
    "        else:\n",
    "            print(f\"Not enough dividend data for {ticker} to calculate growth rate.\")\n",
    "            dividends_df['Growth Rate'] = None\n",
    "        \n",
    "        # Add ticker identifier\n",
    "        dividends_df['Ticker'] = ticker\n",
    "        \n",
    "        # Append to combined DataFrame\n",
    "        dividend_growth_data = pd.concat([dividend_growth_data, dividends_df.reset_index(drop=True)])\n",
    "    else:\n",
    "        print(f\"No dividend data available for {ticker}.\")\n",
    "\n",
    "# Save Dividend Growth Data\n",
    "dividend_growth_data.to_csv(\"dividend_growth_data.csv\", index=False)\n",
    "\n",
    "# Print sample data\n",
    "print(\"Dividend Growth Data:\")\n",
    "print(dividend_growth_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DCF Code Implentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FCF data for AAPL...\n",
      "Processing FCF data for AMZN...\n",
      "Processing FCF data for DIS...\n",
      "Processing FCF data for JNJ...\n",
      "Processing FCF data for KO...\n",
      "Processing FCF data for META...\n",
      "Processing FCF data for MSFT...\n",
      "Processing FCF data for NVDA...\n",
      "Processing FCF data for PG...\n",
      "Processing FCF data for TSLA...\n",
      "FCF projections prepared.\n",
      "Calculating DCF for AAPL...\n",
      "Calculating DCF for AMZN...\n",
      "Calculating DCF for DIS...\n",
      "Calculating DCF for JNJ...\n",
      "Calculating DCF for KO...\n",
      "Calculating DCF for META...\n",
      "Calculating DCF for MSFT...\n",
      "Calculating DCF for NVDA...\n",
      "Calculating DCF for PG...\n",
      "Calculating DCF for TSLA...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Ticker  Enterprise Value  Net Debt  Equity Value  Intrinsic Value per Share\n",
      "0   AAPL      3.194470e+06  242859.0  2.951611e+06                 195.253844\n",
      "1   AMZN      4.093169e+07  238702.0  4.069299e+07                3919.194092\n",
      "2    DIS      2.147888e+05   84695.0  1.300938e+05                  71.795718\n",
      "3    JNJ      4.278144e+05   75857.0  3.519574e+05                 146.217712\n",
      "4   META      4.025355e+06   10953.0  4.014402e+06                1567.513426\n"
     ]
    }
   ],
   "source": [
    "# Load the detailed FCF data\n",
    "fcf_data = pd.read_csv(\"fcf_data_detailed.csv\")\n",
    "\n",
    "# Initialize FCF Projections\n",
    "fcf_projections = {}\n",
    "\n",
    "# Projection parameters\n",
    "projection_years = 5\n",
    "default_growth_rate = 0.05  # Default growth rate if historical growth is unavailable\n",
    "\n",
    "# Process each company\n",
    "for ticker in fcf_data['tic'].unique():\n",
    "    print(f\"Processing FCF data for {ticker}...\")\n",
    "    \n",
    "    # Extract historical FCF for the company\n",
    "    company_fcf = fcf_data[fcf_data['tic'] == ticker].sort_values(by='datadate')\n",
    "    \n",
    "    if len(company_fcf) < 2 or company_fcf['FCF'].iloc[-1] <= 0:\n",
    "        print(f\"Not enough or invalid data for {ticker}. Using default growth rate.\")\n",
    "        historical_growth_rate = default_growth_rate\n",
    "        last_fcf = max(company_fcf['FCF'].iloc[-1], 1)  # Ensure FCF is positive\n",
    "    else:\n",
    "        # Calculate historical growth rate\n",
    "        company_fcf['Growth Rate'] = company_fcf['FCF'].pct_change()\n",
    "        historical_growth_rate = company_fcf['Growth Rate'].mean()\n",
    "        \n",
    "        # Handle invalid growth rates\n",
    "        if pd.isnull(historical_growth_rate) or historical_growth_rate <= 0:\n",
    "            print(f\"Invalid or negative growth rate for {ticker}. Using default.\")\n",
    "            historical_growth_rate = default_growth_rate\n",
    "        \n",
    "        last_fcf = company_fcf['FCF'].iloc[-1]\n",
    "    \n",
    "    # Project future FCF\n",
    "    projected_fcf = [last_fcf * ((1 + historical_growth_rate) ** i) for i in range(1, projection_years + 1)]\n",
    "    \n",
    "    # Save projections\n",
    "    fcf_projections[ticker] = {\n",
    "        'Historical FCF': company_fcf['FCF'].values,\n",
    "        'Historical Growth Rate': historical_growth_rate,\n",
    "        'Projected FCF': projected_fcf\n",
    "    }\n",
    "\n",
    "print(\"FCF projections prepared.\")\n",
    "\n",
    "# Assumptions for DCF\n",
    "WACC = 0.08  # Weighted Average Cost of Capital (8%)\n",
    "terminal_growth_rate = 0.02  # Perpetual growth rate (2%)\n",
    "\n",
    "# Initialize results\n",
    "dcf_results = {}\n",
    "\n",
    "# Process each company\n",
    "for ticker, data in fcf_projections.items():\n",
    "    print(f\"Calculating DCF for {ticker}...\")\n",
    "    \n",
    "    # Projected FCFs and growth rate\n",
    "    projected_fcf = data['Projected FCF']\n",
    "    \n",
    "    # Discount projected FCFs\n",
    "    discounted_fcf = [\n",
    "        fcf / ((1 + WACC) ** i) for i, fcf in enumerate(projected_fcf, start=1)\n",
    "    ]\n",
    "    \n",
    "    # Terminal Value\n",
    "    last_fcf = projected_fcf[-1]\n",
    "    terminal_value = (last_fcf * (1 + terminal_growth_rate)) / (WACC - terminal_growth_rate)\n",
    "    discounted_tv = terminal_value / ((1 + WACC) ** len(projected_fcf))\n",
    "    \n",
    "    # Enterprise Value\n",
    "    enterprise_value = sum(discounted_fcf) + discounted_tv\n",
    "    \n",
    "    # Adjust for net debt\n",
    "    company_data = compustat_data[compustat_data['tic'] == ticker].iloc[-1]\n",
    "    if pd.isnull(company_data['lt']) or pd.isnull(company_data['che']) or pd.isnull(company_data['csho']):\n",
    "        print(f\"Missing data for {ticker}. Skipping DCF.\")\n",
    "        continue\n",
    "    \n",
    "    net_debt = company_data['lt'] - company_data['che']  # Total Liabilities - Cash & Equivalents\n",
    "    equity_value = enterprise_value - net_debt\n",
    "    \n",
    "    # Calculate intrinsic value per share\n",
    "    shares_outstanding = company_data['csho']\n",
    "    intrinsic_value_per_share = equity_value / shares_outstanding\n",
    "    \n",
    "    # Handle invalid intrinsic values\n",
    "    if intrinsic_value_per_share < 0 or pd.isnull(intrinsic_value_per_share):\n",
    "        intrinsic_value_per_share = 0\n",
    "    \n",
    "    # Store results\n",
    "    dcf_results[ticker] = {\n",
    "        'Enterprise Value': enterprise_value,\n",
    "        'Net Debt': net_debt,\n",
    "        'Equity Value': equity_value,\n",
    "        'Intrinsic Value per Share': intrinsic_value_per_share\n",
    "    }\n",
    "\n",
    "# Convert results to DataFrame\n",
    "dcf_results_df = pd.DataFrame.from_dict(dcf_results, orient='index')\n",
    "\n",
    "# Reload the existing DCF results\n",
    "dcf_results = pd.read_csv(\"dcf_results.csv\", index_col=0)\n",
    "\n",
    "# Reset the index to include Ticker as a column\n",
    "dcf_results.reset_index(inplace=True)\n",
    "\n",
    "# Rename the index column (if it exists) to Ticker\n",
    "if 'index' in dcf_results.columns:\n",
    "    dcf_results.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "\n",
    "# Save the corrected file without including the index\n",
    "dcf_results.to_csv(\"dcf_results_corrected.csv\", index=False)\n",
    "\n",
    "# Verify the corrected file\n",
    "print(dcf_results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA Valuation for AAPL:\n",
      "P/E-based Valuation: $2,301,215.06\n",
      "EV/EBITDA-based Valuation: $69,996.67\n",
      "CCA Valuation for MSFT:\n",
      "P/E-based Valuation: $3,082,638.58\n",
      "EV/EBITDA-based Valuation: $258,659.05\n",
      "Error processing GOOG: single positional indexer is out-of-bounds\n",
      "CCA Valuation for AMZN:\n",
      "P/E-based Valuation: $1,577,593.02\n",
      "EV/EBITDA-based Valuation: $201,875.00\n",
      "CCA Valuation for TSLA:\n",
      "P/E-based Valuation: $628,459.80\n",
      "EV/EBITDA-based Valuation: $51,316.59\n",
      "CCA Valuation for NVDA:\n",
      "P/E-based Valuation: $1,540,102.99\n",
      "EV/EBITDA-based Valuation: $81,817.37\n",
      "CCA Valuation for META:\n",
      "P/E-based Valuation: $718,310.64\n",
      "EV/EBITDA-based Valuation: $170,704.32\n",
      "CCA Valuation for JNJ:\n",
      "P/E-based Valuation: $841,192.06\n",
      "EV/EBITDA-based Valuation: $69,379.31\n",
      "CCA Valuation for PG:\n",
      "P/E-based Valuation: $347,414.43\n",
      "EV/EBITDA-based Valuation: $52,053.76\n",
      "CCA Valuation for DIS:\n",
      "P/E-based Valuation: $272,010.17\n",
      "EV/EBITDA-based Valuation: $133,023.80\n",
      "Sample CCA Results:\n",
      "  Ticker  P/E Median  EV/EBITDA Median  P/E Valuation  EV/EBITDA Valuation\n",
      "0   AAPL   24.549960          0.532634   2.301215e+06         69996.668946\n",
      "1   MSFT   34.975930          1.998401   3.082639e+06        258659.045671\n",
      "2   AMZN   51.851866          2.975576   1.577593e+06        201875.000000\n",
      "3   TSLA   41.905701          3.784968   6.284598e+05         51316.590835\n",
      "4   NVDA   51.750773          2.372893   1.540103e+06         81817.366028\n"
     ]
    }
   ],
   "source": [
    "# Ensure required columns exist\n",
    "required_columns = ['tic', 'datadate', 'csho', 'prcc_f', 'ni', 'at', 'lt', 'oibdp', 'naicsh']\n",
    "if not all(col in compustat_data.columns for col in required_columns):\n",
    "    raise ValueError(\"One or more required columns are missing from the data.\")\n",
    "\n",
    "# Calculate Valuation Multiples\n",
    "compustat_data['Market Cap'] = compustat_data['csho'] * compustat_data['prcc_f']\n",
    "compustat_data['P/E'] = compustat_data['Market Cap'] / compustat_data['ni'].replace(0, np.nan)\n",
    "compustat_data['EV'] = compustat_data['at'] - compustat_data['lt']  # Enterprise Value\n",
    "compustat_data['EV/EBITDA'] = compustat_data['EV'] / compustat_data['oibdp'].replace(0, np.nan)\n",
    "\n",
    "# Filter relevant columns for peers\n",
    "peer_data = compustat_data[['tic', 'naicsh', 'P/E', 'EV/EBITDA']]\n",
    "\n",
    "# Group by NAICS to find peers\n",
    "peer_multiples = peer_data.groupby('naicsh').agg({\n",
    "    'P/E': ['mean', 'median'],\n",
    "    'EV/EBITDA': ['mean', 'median']\n",
    "}).reset_index()\n",
    "peer_multiples.columns = ['NAICSH', 'P/E Mean', 'P/E Median', 'EV/EBITDA Mean', 'EV/EBITDA Median']\n",
    "\n",
    "# Save peer multiples to CSV\n",
    "peer_multiples.to_csv(\"peer_multiples.csv\", index=False)\n",
    "\n",
    "# Initialize results dictionary\n",
    "cca_results = {}\n",
    "\n",
    "# Iterate through all target tickers\n",
    "for target_ticker in [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \"NVDA\", \"META\", \"JNJ\", \"PG\", \"DIS\"]:\n",
    "    try:\n",
    "        # Get target company's data\n",
    "        target_data = compustat_data[compustat_data['tic'] == target_ticker].iloc[-1]\n",
    "\n",
    "        # Fetch target company's metrics\n",
    "        target_ebitda = target_data['oibdp']\n",
    "        target_net_income = target_data['ni']\n",
    "\n",
    "        # Find peer group multiples (based on NAICS)\n",
    "        naics_code = target_data['naicsh']\n",
    "        target_peer_multiples = peer_multiples[peer_multiples['NAICSH'] == naics_code]\n",
    "\n",
    "        if not target_peer_multiples.empty:\n",
    "            pe_median = target_peer_multiples['P/E Median'].values[0]\n",
    "            ev_ebitda_median = target_peer_multiples['EV/EBITDA Median'].values[0]\n",
    "\n",
    "            # Valuation estimates\n",
    "            pe_valuation = pe_median * target_net_income\n",
    "            ev_valuation = ev_ebitda_median * target_ebitda\n",
    "\n",
    "            # Store results\n",
    "            cca_results[target_ticker] = {\n",
    "                'P/E Median': pe_median,\n",
    "                'EV/EBITDA Median': ev_ebitda_median,\n",
    "                'P/E Valuation': pe_valuation,\n",
    "                'EV/EBITDA Valuation': ev_valuation\n",
    "            }\n",
    "\n",
    "            # Print results for each company\n",
    "            print(f\"CCA Valuation for {target_ticker}:\")\n",
    "            print(f\"P/E-based Valuation: ${pe_valuation:,.2f}\")\n",
    "            print(f\"EV/EBITDA-based Valuation: ${ev_valuation:,.2f}\")\n",
    "        else:\n",
    "            print(f\"No peer multiples found for NAICS code: {naics_code} (Ticker: {target_ticker})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {target_ticker}: {e}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "cca_results_df = pd.DataFrame.from_dict(cca_results, orient='index').reset_index()\n",
    "\n",
    "# Rename the index column to 'Ticker'\n",
    "cca_results_df.rename(columns={'index': 'Ticker'}, inplace=True)\n",
    "\n",
    "# Save results to CSV\n",
    "cca_results_df.to_csv(\"cca_results_corrected.csv\", index=False)\n",
    "\n",
    "# Print sample results\n",
    "print(\"Sample CCA Results:\")\n",
    "print(cca_results_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CODE for DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dividend data available for AMZN. Skipping DDM.\n",
      "No dividend data available for META. Skipping DDM.\n",
      "No dividend data available for TSLA. Skipping DDM.\n",
      "Finalized DDM Results Saved to 'final_ddm_results.csv'\n",
      "  Ticker  Most Recent Dividend Dividend Growth Rate Intrinsic Value\n",
      "0   AAPL                  0.98                 0.05            34.3\n",
      "1    DIS                  0.75                 0.05           26.25\n",
      "2    JNJ                  4.70              0.05833      229.544059\n",
      "3     KO                  1.84             0.033621       41.006953\n",
      "4   MSFT                  2.93             0.100445             0.0\n"
     ]
    }
   ],
   "source": [
    "# Required rate of return\n",
    "required_rate_of_return = 0.08  # 8% return\n",
    "\n",
    "# Filter relevant columns\n",
    "ddm_data = compustat_data[['tic', 'datadate', 'dvpsp_f']].copy()\n",
    "\n",
    "# Ensure data is sorted by ticker and date\n",
    "ddm_data['datadate'] = pd.to_datetime(ddm_data['datadate'])  # Ensure datadate is a datetime object\n",
    "ddm_data = ddm_data.sort_values(by=['tic', 'datadate'])\n",
    "\n",
    "# Initialize results list\n",
    "ddm_results_list = []\n",
    "\n",
    "# Process each ticker\n",
    "for ticker in ddm_data['tic'].unique():\n",
    "    company_data = ddm_data[ddm_data['tic'] == ticker].copy()\n",
    "    \n",
    "    # Remove rows with missing or zero dividends\n",
    "    company_data = company_data[company_data['dvpsp_f'] > 0]\n",
    "    if company_data.empty:\n",
    "        print(f\"No dividend data available for {ticker}. Skipping DDM.\")\n",
    "        continue\n",
    "    \n",
    "    # Calculate most recent dividend\n",
    "    most_recent_dividend = company_data['dvpsp_f'].iloc[-1]\n",
    "    \n",
    "    # Calculate average dividend growth rate\n",
    "    if len(company_data) > 1:\n",
    "        company_data['Growth Rate'] = company_data['dvpsp_f'].pct_change()\n",
    "        dividend_growth_rate = company_data['Growth Rate'].mean()\n",
    "    else:\n",
    "        dividend_growth_rate = 0.05  # Default growth rate for limited data\n",
    "    \n",
    "    # Handle invalid or negative growth rates\n",
    "    if dividend_growth_rate <= 0 or pd.isnull(dividend_growth_rate):\n",
    "        dividend_growth_rate = 0.05  # Default growth rate\n",
    "    \n",
    "    # Calculate Intrinsic Value using DDM\n",
    "    try:\n",
    "        next_year_dividend = most_recent_dividend * (1 + dividend_growth_rate)\n",
    "        intrinsic_value = next_year_dividend / (required_rate_of_return - dividend_growth_rate)\n",
    "    except ZeroDivisionError:\n",
    "        intrinsic_value = 0  # If (required_rate_of_return - dividend_growth_rate) is zero\n",
    "    \n",
    "    # Append to results list\n",
    "    ddm_results_list.append({\n",
    "        'Ticker': ticker,\n",
    "        'Most Recent Dividend': most_recent_dividend,\n",
    "        'Dividend Growth Rate': dividend_growth_rate,\n",
    "        'Intrinsic Value': intrinsic_value\n",
    "    })\n",
    "\n",
    "# Convert results list to DataFrame\n",
    "ddm_results = pd.DataFrame(ddm_results_list)\n",
    "\n",
    "# Validate Intrinsic Values\n",
    "ddm_results['Intrinsic Value'] = ddm_results['Intrinsic Value'].apply(\n",
    "    lambda x: max(x, 0) if pd.notnull(x) else 'Not Applicable'\n",
    ")\n",
    "\n",
    "# Add missing companies with \"Not Applicable\" results\n",
    "missing_tickers = set([\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \"NVDA\", \"META\", \"JNJ\", \"PG\", \"DIS\"]) - set(ddm_results['Ticker'])\n",
    "for ticker in missing_tickers:\n",
    "    ddm_results = pd.concat([ddm_results, pd.DataFrame({\n",
    "        'Ticker': [ticker],\n",
    "        'Most Recent Dividend': [0],\n",
    "        'Dividend Growth Rate': ['N/A'],\n",
    "        'Intrinsic Value': ['Not Applicable']\n",
    "    })], ignore_index=True)\n",
    "\n",
    "# Save Finalized DDM Results to CSV\n",
    "ddm_results.to_csv(\"final_ddm_results.csv\", index=False)\n",
    "\n",
    "# Print Finalized Results\n",
    "print(\"Finalized DDM Results Saved to 'final_ddm_results.csv'\")\n",
    "print(ddm_results.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Consolidated Valuation Results Saved to 'final_valuation_results_with_prices.csv'\n",
      "  Ticker  Enterprise Value  Net Debt  Equity Value  Intrinsic Value per Share  \\\n",
      "0   AAPL      3.194470e+06  242859.0  2.951611e+06                   0.026451   \n",
      "1   AMZN      4.093169e+07  238702.0  4.069299e+07                   0.530926   \n",
      "2    DIS      2.147888e+05   84695.0  1.300938e+05                   0.009726   \n",
      "3   GOOG               NaN       NaN           NaN                   0.000000   \n",
      "4    JNJ      4.278144e+05   75857.0  3.519574e+05                   0.019808   \n",
      "\n",
      "   P/E Median  EV/EBITDA Median  P/E Valuation  EV/EBITDA Valuation  \\\n",
      "0   24.549960          0.532634       0.746508         69996.668946   \n",
      "1   51.851866          2.975576       0.511767        201875.000000   \n",
      "2   54.708401          7.869368       0.088239        133023.803913   \n",
      "3         NaN               NaN       0.000000                  NaN   \n",
      "4   23.929453          2.281164       0.272881         69379.314371   \n",
      "\n",
      "   Most Recent Dividend  Dividend Growth Rate  Intrinsic Value  \\\n",
      "0                  0.98               0.05000         0.149427   \n",
      "1                  0.00                   NaN         0.000000   \n",
      "2                  0.75               0.05000         0.114357   \n",
      "3                  0.00                   NaN         0.000000   \n",
      "4                  4.70               0.05833         1.000000   \n",
      "\n",
      "   Weighted Valuation  Current Price  Valuation Ratio Valuation Category  \n",
      "0            0.339069     243.000000         0.001395         Overvalued  \n",
      "1            0.417077     222.059998         0.001878         Overvalued  \n",
      "2            0.062058     116.690002         0.000532         Overvalued  \n",
      "3            0.000000     175.240005         0.000000         Overvalued  \n",
      "4            0.317075     149.259995         0.002124         Overvalued  \n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load Corrected DataFrames\n",
    "dcf_results = pd.read_csv(\"dcf_results_corrected.csv\")\n",
    "cca_results = pd.read_csv(\"cca_results_corrected.csv\")\n",
    "ddm_results = pd.read_csv(\"final_ddm_results.csv\")\n",
    "\n",
    "# Ensure consistent column names\n",
    "dcf_results.rename(columns={'tic': 'Ticker', 'ticker': 'Ticker'}, inplace=True)\n",
    "cca_results.rename(columns={'tic': 'Ticker', 'ticker': 'Ticker'}, inplace=True)\n",
    "ddm_results.rename(columns={'tic': 'Ticker', 'ticker': 'Ticker'}, inplace=True)\n",
    "\n",
    "# Merge DataFrames\n",
    "valuation_results = pd.merge(dcf_results, cca_results, on='Ticker', how='outer')\n",
    "valuation_results = pd.merge(valuation_results, ddm_results, on='Ticker', how='outer')\n",
    "\n",
    "# Handle Missing Values\n",
    "valuation_results.fillna({\n",
    "    'Intrinsic Value per Share': 'N/A',\n",
    "    'P/E Valuation': 'N/A',\n",
    "    'Intrinsic Value': 'N/A'\n",
    "}, inplace=True)\n",
    "\n",
    "# Safely replace 'N/A' and non-numeric values with 0 and convert to float\n",
    "valuation_results['Intrinsic Value per Share'] = pd.to_numeric(\n",
    "    valuation_results['Intrinsic Value per Share'], errors='coerce').fillna(0)\n",
    "valuation_results['P/E Valuation'] = pd.to_numeric(\n",
    "    valuation_results['P/E Valuation'], errors='coerce').fillna(0)\n",
    "valuation_results['Intrinsic Value'] = pd.to_numeric(\n",
    "    valuation_results['Intrinsic Value'], errors='coerce').fillna(0)\n",
    "\n",
    "# Normalize values to a common scale\n",
    "valuation_results['Intrinsic Value per Share'] = (\n",
    "    valuation_results['Intrinsic Value per Share'] / valuation_results['Intrinsic Value per Share'].max()\n",
    ")\n",
    "valuation_results['P/E Valuation'] = (\n",
    "    valuation_results['P/E Valuation'] / valuation_results['P/E Valuation'].max()\n",
    ")\n",
    "valuation_results['Intrinsic Value'] = (\n",
    "    valuation_results['Intrinsic Value'] / valuation_results['Intrinsic Value'].max()\n",
    ")\n",
    "\n",
    "# Define weights for valuation models\n",
    "weights = {\n",
    "    'DCF': 0.4,  # 40% weight for DCF\n",
    "    'CCA': 0.4,  # 40% weight for CCA\n",
    "    'DDM': 0.2   # 20% weight for DDM\n",
    "}\n",
    "\n",
    "# Calculate Weighted Valuation\n",
    "valuation_results['Weighted Valuation'] = (\n",
    "    valuation_results['Intrinsic Value per Share'] * weights['DCF'] +\n",
    "    valuation_results['P/E Valuation'] * weights['CCA'] +\n",
    "    valuation_results['Intrinsic Value'] * weights['DDM']\n",
    ")\n",
    "\n",
    "# Fetch current prices using yfinance\n",
    "tickers = valuation_results['Ticker'].unique()\n",
    "current_prices = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        price = stock.history(period=\"1d\")[\"Close\"].iloc[-1]  # Fetch the last closing price\n",
    "        current_prices[ticker] = price\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching price for {ticker}: {e}\")\n",
    "        current_prices[ticker] = None\n",
    "\n",
    "# Add current prices to the DataFrame\n",
    "valuation_results['Current Price'] = valuation_results['Ticker'].map(current_prices)\n",
    "\n",
    "# Handle missing prices\n",
    "valuation_results['Current Price'] = valuation_results['Current Price'].fillna(0)\n",
    "\n",
    "# Calculate Valuation Ratio\n",
    "valuation_results['Valuation Ratio'] = valuation_results['Weighted Valuation'] / valuation_results['Current Price']\n",
    "\n",
    "# Categorize as Undervalued or Overvalued\n",
    "valuation_results['Valuation Category'] = valuation_results['Valuation Ratio'].apply(\n",
    "    lambda x: 'Undervalued' if x > 1 else 'Overvalued'\n",
    ")\n",
    "\n",
    "# Save Final Consolidated Results\n",
    "valuation_results.to_csv(\"final_valuation_results_with_prices.csv\", index=False)\n",
    "\n",
    "# Print Final Consolidated Results\n",
    "print(\"Final Consolidated Valuation Results Saved to 'final_valuation_results_with_prices.csv'\")\n",
    "print(valuation_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
